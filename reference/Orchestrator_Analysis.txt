24. modules/orchestrator.js
  * Purpose: This module acts as a high-level story analyst or "director". It is designed to run periodically (e.g., every 4 chapters) 
     to review the recent story progress and generate structured feedback. This prevents narrative drift and improves long-term coherence.
     **The integration of the `TurnContext` object is crucial here, as it provides the orchestrator with seamless access to the full chapter history, including previous director's feedback, enabling a more informed and coherent narrative steering.**
  * Configuration (CONFIG object):
      * THINKING_MODEL: Specifies the LLM model to be used for orchestrator tasks (from settings.json).
      * CHAPTERS_TO_REVIEW: Number of most recent chapters to include in the context for periodic review.
      * LLM_PARAMS: Parameters for the LLM call (e.g., temperature, max_tokens, reasoning: { exclude: true }).
      * OUTPUT_DELIMITER: A string used to split the LLM's response into director feedback and writer's brief.
  * Main Functions:
      * createOrchestratorTurn0Prompt(lorebook, initialPremise): Creates the prompt for the orchestrator LLM for the initial Turn 0.
      * createOrchestratorPrompt(recentHistory, lastSelfFeedback): Creates the prompt for the orchestrator LLM for periodic reviews, including recent history and previous self-feedback.
      * _runOrchestratorLLM(prompt): An internal helper function that handles the LLM call, logging, and parsing of the response. It splits the LLM's output into directorfeedback and writerfeedback.
      * runTurn0(lorebook, initialPremise): Runs the proactive orchestrator process for Turn 0, generating initial feedback based on the lorebook and premise.
      * runPeriodic(turnContext): Runs the reactive, periodic orchestrator process. **By receiving the `TurnContext` object, it efficiently retrieves the full chapter history using `turnContext.retrieveDatedChapters()`, finds the last self-feedback from the chapter properties, gathers recent chapters, and calls the LLM to generate new feedback, all within a streamlined data structure. This process is robust to failures in underlying RAG or summarization services, which will gracefully degrade.**
  * Modularity: Good. It receives data (now encapsulated in `TurnContext`), processes it via an API call, and returns a result. It also logs LLM prompts and responses to files.
  * Dependencies: utils.js (for Logger, openrouterRequest, readSettings, readFileSync), path, fs/promises.
  * Flow Analysis:
      * Triggered by `vnmanager.js` during the VN transformation pipeline (for `runPeriodic`) or potentially at the very beginning of a new story (for `runTurn0`).
      * For `runPeriodic`, it now receives the `TurnContext` object directly.
      * It uses `turnContext.retrieveDatedChapters()` to get the full chapter history.
      * It finds its own last `directorfeedback` from the history for analytical continuity.
      * It generates new feedback (`writerfeedback` and `directorfeedback`) by calling the configured thinking model.
      * This feedback is returned up to `vnmanager`, then to `main.js`, then to the renderer.
      * The renderer then includes this feedback in the `auxobj` when calling `save-message-chapter`, permanently associating it with the current story turn.
      * **The `TurnContext` object significantly simplifies the data flow to the orchestrator, ensuring it has all necessary information for informed decision-making without complex parameter passing.**