Configuration and Utilities Analysis:

This document outlines the functionality and implementation details of the `modules/utils.js` file and the `settings.json` configuration.

### 5. modules/utils.js (Shared Utilities)

*   **Purpose:** Provides a collection of common utility functions used across various modules in the project. This includes logging, file system operations, string manipulation, hashing, API requests (specifically OpenRouter and Gemini), and progress reporting. It also handles the loading and exposure of application settings from `settings.json`.
*   **Main Functions:**
    *   `loadSettings()`: Loads application settings from `settings.json` at startup.
    *   `Logger` (object with `log`, `error`): A custom logging utility that respects the `debug` setting from `settings.json`.
    *   `TurnLogger`: A module for managing turn-based log files, ensuring logs are written asynchronously and can be retrieved.
        *   `startNewTurnLog(projectName)`: Initializes a new log file for a turn within a project-specific subdirectory (`logs/<projectName>/`).
        *   `log(title, content)`: Queues a log entry for the current turn.
        *   `getCurrentLogPath()`: Returns the path of the current log file.
        *   `getLatestLogPath()`: Finds the path of the most recent log file.
        *   `readLatestLog()`: Reads and parses the content of the most recent log file.
    *   `readFileSync(relPath)`: Reads a file synchronously from the project root.
    *   `ensureDirectoryExists(dirPath)`: Asynchronously creates directories if they don't exist.
    *   `ensureDirectoryExistsSync(dirPath)`: Synchronously creates directories if they don't exist.
    *   `listFilesRecursive(dir, validExtensions)`: Recursively lists files in a directory with specific extensions.
    *   `appendToFile(filePath, content)`: Appends content to a file.
    *   `replaceAll(str, search, replacement)`: Replaces all occurrences of a substring in a string.
    *   `generateHash(content, algorithm)`: Generates a hash for the given content.
    *   `normalizeText(text)`: Normalizes text for comparison (lowercase, replaces spaces with underscores).
    *   `getFilename(filepath)`: Extracts the filename from a full path.
    *   `openrouterRequest({ messages, model, extra })`: Makes a request to the OpenRouter API.
    *   `transformMessagesForGemini(messages)`: Transforms messages from OpenAI format to Gemini format.
    *   `requestGeminiWithFallback({ messages, fallbackModel, extra })`: Makes a request to a primary model (Gemini) and falls back to OpenRouter if the primary call fails.
    *   `reportProgress(socket, { step, totalSteps, status, startTime })`: Reports progress via a socket.
    *   `naturalSort(a, b)`: Natural sort comparison function for file/folder names.
*   **Modularity:** Excellent. It's a pure utility module with no external dependencies beyond Node.js built-ins and `axios`. It's designed to be imported and used by other modules without creating circular dependencies.
*   **Dependencies:** `fs/promises`, `fs`, `path`, `crypto`, `axios`.
*   **Flow Analysis:** Provides foundational services. For example, `openrouterRequest` and `requestGeminiWithFallback` are crucial for all LLM interactions, `Logger` for debugging, and file system functions for data persistence. The `TurnLogger` is essential for debugging and understanding the flow of the application by logging turn-based data.

### settings.json (Application Configuration)

*   **Purpose:** This JSON file serves as the central configuration hub for the entire application. It defines various parameters that control the behavior of different modules, including API keys, model selections, LLM parameters, and feature toggles.
*   **Key Sections and Their Purpose:**
    *   `debug`: Boolean. If `true`, enables verbose logging across the application.
    *   `openrouter`: Configuration for the OpenRouter API.
        *   `url`: The endpoint for OpenRouter API.
        *   `apiKey`: Your OpenRouter API key.
        *   `thinkingmodel`, `highendmodel`, `mediumendmodel`, `lowendmodel`: Defines different LLM models available through OpenRouter for various tasks, categorized by their perceived "power" or cost.
    *   `writer`: Configuration for the main narrative writing LLM.
        *   `model`: Specifies which OpenRouter model (e.g., `highendmodel`) to use for writing.
        *   `llm_params`: Parameters passed to the LLM for text generation (e.g., `frequency_penalty`, `presence_penalty`, `temperature`, `top_p`, `reasoning`).
    *   `orchestrator`: Configuration for the orchestrator module.
        *   `model`: Specifies which OpenRouter model (e.g., `thinkingmodel`) to use for orchestrator tasks.
        *   `llm_params`: Parameters for the orchestrator LLM.
        *   `chapters_to_review`: Number of recent chapters the orchestrator should review.
    *   `gemini`: Configuration for the Google Gemini API.
        *   `baseUrl`: The base URL for the Gemini API.
        *   `apiKey`: Your Google AI Studio API key.
        *   `model`: The specific Gemini model to use (e.g., `gemini-2.5-pro`).
    *   `chroma`: Configuration for the ChromaDB vector store.
        *   `url`: The URL where the ChromaDB server is running.
    *   `ollama`: Configuration for the Ollama embeddings model.
        *   `model`: The Ollama model to use for generating embeddings (e.g., `nomic-embed-text`).
        *   `baseUrl`: The base URL for the Ollama server.
    *   `assetSelector`: Configuration for selecting visual novel assets (backgrounds, OSTs).
        *   `enableOST`, `enableBackground`: Booleans to enable/disable OST and background selection.
        *   `background_model`, `ost_model`: Models to use for LLM-based asset selection.
        *   `background_params`, `ost_params`: LLM parameters for asset selection.
    *   `enableTTS`: Boolean. If `true`, enables Text-to-Speech generation.
    *   `ttsApiEndpoint`: The endpoint for the external TTS API.
    *   `emotionClassifier`: Configuration for character emotion classification.
        *   `enabled`: Boolean to enable/disable emotion classification.
        *   `model`: Model to use for emotion classification.
        *   `llm_params`: LLM parameters for emotion classification.
    *   `useUncensorifyPrompt`: Boolean. If `true`, uses an "uncensorify" prompt for dialogue transformation.
    *   `dialogue_processor`: Configuration for the dialogue processing module.
        *   `model`: Model to use for dialogue transformation.
        *   `llm_params`: LLM parameters for dialogue transformation.
        *   `enabled`: Boolean to enable/disable dialogue processing.
    *   `player_choice_generator`: Configuration for generating player choices.
        *   `model`: Model to use for player choice generation.
        *   `llm_params`: LLM parameters for player choice generation.
        *   `enabled`: Boolean to enable/disable player choice generation.
*   **Impact on Application Behavior:** `settings.json` directly influences the application's behavior, from which LLM models are used for different tasks to whether TTS is enabled or how verbose the logging is. Changes to this file allow for easy customization and tuning of the application without modifying code.
*   **Relationship with `modules/utils.js`:** The `modules/utils.js` file is responsible for loading these settings at application startup, making them accessible to other modules via the `settings` object. This centralizes configuration management.
