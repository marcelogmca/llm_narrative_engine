  24. modules/orchestrator.js
  * Purpose: This module acts as a high-level story analyst or "director". It is designed to run periodically (e.g., every 4 chapters) 
     to review the recent story progress and generate structured feedback. This prevents narrative drift and improves long-term coherence.
     It searches backwards through the properties array (provided by chaptermanagement) to find its own last 'director's feedback'.
  * Configuration (CONFIG object):
      * THINKING_MODEL: Specifies the LLM model to be used for orchestrator tasks (from settings.json).
      * CHAPTERS_TO_REVIEW: Number of most recent chapters to include in the context for periodic review.
      * LLM_PARAMS: Parameters for the LLM call (e.g., temperature, max_tokens, reasoning: { exclude: true }).
      * OUTPUT_DELIMITER: A string used to split the LLM's response into director feedback and writer's brief.
  * Main Functions:
      * createOrchestratorTurn0Prompt(lorebook, initialPremise): Creates the prompt for the orchestrator LLM for the initial Turn 0.
      * createOrchestratorPrompt(recentHistory, lastSelfFeedback): Creates the prompt for the orchestrator LLM for periodic reviews, including recent history and previous self-feedback.
      * _runOrchestratorLLM(prompt): An internal helper function that handles the LLM call, logging, and parsing of the response. It splits the LLM's output into directorfeedback and writerfeedback.
      * runTurn0(lorebook, initialPremise): Runs the proactive orchestrator process for Turn 0, generating initial feedback based on the lorebook and premise.
      * runPeriodic(chapters, properties): Runs the reactive, periodic orchestrator process. It finds the last self-feedback from the chapter properties, gathers recent chapters, and calls the LLM to generate new feedback.
  * Modularity: Good. It receives data, processes it via an API call, and returns a result. It also logs LLM prompts and responses to files.
  * Dependencies: utils.js (for Logger, openrouterRequest, readSettings, readFileSync), path, fs/promises.
  * Flow Analysis:
      * Triggered by vnmanager_simple.js during the VN transformation pipeline (for runPeriodic) or potentially at the very beginning of a new story (for runTurn0).
      * It receives the full chapter history (chapters text and properties objects) for runPeriodic.
      * It finds its own last directorfeedback from the history for analytical continuity.
      * It generates new feedback (writerfeedback and directorfeedback) by calling the configured thinking model.
      * This feedback is returned up to vnmanager, then to main.js, then to the renderer.
      * The renderer then includes this feedback in the auxobj when calling save-message-chapter, permanently associating it with the current story turn.
